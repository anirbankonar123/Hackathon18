{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# This notebook is to explore various prediction models from the Used Car Price data \n",
    "at : https://www.kaggle.com/CooperUnion/cardataset\n",
    "Various Regression techniques are explored, with K-fold cross validation, grid search of parameters, including \n",
    "Deep Learning techniques and the best approach is selected based on Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import all necessary libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense   \n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Read the pre-processed pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5556, 50)\n",
      "(5556, 68)\n"
     ]
    }
   ],
   "source": [
    "train_X=pd.read_pickle('C:/users/hackuser1/Hackathon18/train_X_ord.pkl')\n",
    "test_X=pd.read_pickle('C:/users/hackuser1/Hackathon18/test_X_ord.pkl')\n",
    "train_Y=pd.read_pickle('C:/users/hackuser1/Hackathon18/train_Y_ord.pkl') # train Y with log(MSRP)\n",
    "test_Y=pd.read_pickle('C:/users/hackuser1/Hackathon18/test_Y_ord.pkl')\n",
    "train_Y_orig=pd.read_pickle('C:/users/hackuser1/Hackathon18/train_Y_ord_orig.pkl') # train Y with MSRP unmodified\n",
    "test_Y_orig=pd.read_pickle('C:/users/hackuser1/Hackathon18/test_Y_ord_orig.pkl')\n",
    "\n",
    "train_X_make=pd.read_pickle('C:/users/hackuser1/Hackathon18/train_X_ord_make.pkl')\n",
    "test_X_make=pd.read_pickle('C:/users/hackuser1/Hackathon18/test_X_ord_make.pkl')\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_X_make.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit Sklearn LinearRegression and use this to make predictions on the test data and check the RMSE\n",
    "Use train X data with make and without make, and Test Y as MSRP as well as Log MSRP and compare the RMSE values on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit train data without make info, and log MSRP\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(train_X, train_Y)\n",
    "\n",
    "#fit train data without make and MSRP, as it\n",
    "lin_reg_1 = LinearRegression()\n",
    "lin_reg_1.fit(train_X, train_Y_orig)\n",
    "\n",
    "#fit train data with make and log MSRP\n",
    "lin_reg_make = LinearRegression()\n",
    "lin_reg_make.fit(train_X_make, train_Y)\n",
    "\n",
    "#fit train data with make and MSRP, as it\n",
    "lin_reg_make1 = LinearRegression()\n",
    "lin_reg_make1.fit(train_X_make, train_Y_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse without make, log MSRP:8682.51038042\n",
      "rmse without make, MSRP, as is:28154.1680349\n",
      "rmse with make, log MSRP:8264.94537965\n",
      "rmse with make, MSRP, as is:28111.9382669\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = lin_reg.predict(test_X)\n",
    "lin_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"rmse without make, log MSRP:\"+str(lin_rmse))\n",
    "\n",
    "carSales_predictions = lin_reg_1.predict(test_X)\n",
    "lin_mse = mean_squared_error(test_Y, carSales_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"rmse without make, MSRP, as is:\"+str(lin_rmse))\n",
    "\n",
    "carSales_predictions = lin_reg_make.predict(test_X_make)\n",
    "lin_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"rmse with make, log MSRP:\"+str(lin_rmse))\n",
    "\n",
    "carSales_predictions = lin_reg_make1.predict(test_X_make)\n",
    "lin_mse = mean_squared_error(test_Y, carSales_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"rmse with make, MSRP, as is:\"+str(lin_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We observe the data with make and log MSRP gives best results. We use this data to fit subsequent algorithms.\n",
    "Next we use SGDRegressor from scikit learn and compare the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=500, n_iter=None, penalty=None,\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg_make = SGDRegressor(max_iter=500,penalty=None,eta0=0.01)\n",
    "sgd_reg_make.fit(train_X_make, train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD RMSE:8431.27891031\n",
      "predicted prices\n",
      "[ 10371.00490086  24001.28137027  12242.73134155   4099.57650418\n",
      "  26316.7917553 ]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions_make = sgd_reg_make.predict(test_X_make)\n",
    "sgd_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions_make))\n",
    "sgd_rmse = np.sqrt(sgd_mse)\n",
    "print(\"SGD RMSE:\"+str(sgd_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions_make[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(train_X,train_Y)\n",
    "\n",
    "tree_reg_make = DecisionTreeRegressor()\n",
    "tree_reg_make.fit(train_X_make,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE, without make:3226.04648531\n",
      "predicted prices\n",
      "[ 21908.36292378  22206.          21696.           2001.          27786.        ]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = tree_reg.predict(test_X)\n",
    "tree_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(\"Decision Tree RMSE, without make:\"+str(tree_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE, with make:3306.46053247\n",
      "predicted prices\n",
      "[ 21986.  22206.  21696.   2001.  27786.]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions_make = tree_reg_make.predict(test_X_make)\n",
    "tree_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions_make))\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(\"Decision Tree RMSE, with make:\"+str(tree_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions_make[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find Decision tree without make data included reduces the RMSE and is the best so far. We \n",
    "validate this using K-fold Cross validation with k set to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [ 0.11083209  0.11231012  0.10701108  0.11265773  0.1051632   0.11883144\n",
      "  0.11107944  0.10983457  0.10684469  0.10395923]\n",
      "mean: 0.109852359536\n",
      "std dev: 0.00413323795067\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(tree_reg,train_X,train_Y,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\"scores:\",tree_rmse_scores)\n",
    "print(\"mean:\",tree_rmse_scores.mean())\n",
    "print(\"std dev:\",tree_rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows there is a good fit, and there is very less variation between the folds and the data is dependable.\n",
    "We now try RandomForestRegressor, with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg_make = RandomForestRegressor()\n",
    "forest_reg_make.fit(train_X_make,train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor RMSE, with make:3007.89473227\n",
      "predicted prices\n",
      "[ 21986.  22206.  21696.   2001.  27786.]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = forest_reg_make.predict(test_X_make)\n",
    "forest_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print(\"Random Forest Regressor RMSE, with make:\"+str(forest_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions_make[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly a better fit compared to DecisionTree, and we validate this with k-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [ 0.1003288   0.10236403  0.0970677   0.10109563  0.09460684  0.10117497\n",
      "  0.1001396   0.10114034  0.10542622  0.0945154 ]\n",
      "mean: 0.099785953653\n",
      "std dev: 0.00326111465624\n"
     ]
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest_reg_make,train_X_make,train_Y.values.ravel(),scoring=\"neg_mean_squared_error\",cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "\n",
    "print(\"scores:\",forest_rmse_scores)\n",
    "print(\"mean:\",forest_rmse_scores.mean())\n",
    "print(\"std dev:\",forest_rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use GridSearch to find the optimum parameters for RandomForestRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMETERS FOR RANDOM FOREST REGRESSOR IS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'n_estimators': 30}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(train_X_make, train_Y.values.ravel())\n",
    "print(\"BEST PARAMETERS FOR RANDOM FOREST REGRESSOR IS:\")\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=30, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit using best parameters and check\n",
    "forest_reg_make = RandomForestRegressor(max_features=8,n_estimators=30)\n",
    "forest_reg_make.fit(train_X_make,train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor RMSE, with make:3005.64852571\n",
      "predicted prices\n",
      "[ 21986.  22206.  21696.   2001.  27786.]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = forest_reg_make.predict(test_X_make)\n",
    "forest_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print(\"Random Forest Regressor RMSE, with make:\"+str(forest_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions_make[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observation is : Default parameters gives better results.\n",
    "We now find the feature importances from the GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.46593890501651097, 'Age'), (0.098148170566372483, 'Engine HP fourth'), (0.076299195994136634, 'Engine HP'), (0.066089702307533596, 'Engine HP sq'), (0.051723005625070255, 'Engine HP cu'), (0.042397648482941017, 'City MPG'), (0.023080738500653907, 'MANUAL'), (0.02195848453347125, 'regular unleaded'), (0.020503807206899895, 'AUTOMATIC'), (0.011149896053947918, 'Large'), (0.0088207727040695572, '6.'), (0.007980354616572382, 'Oldsmobile'), (0.007826412105500594, '8.'), (0.0062016341619253231, '4.'), (0.0054618636416263137, '4dr SUV'), (0.0053992348662030721, '2dr SUV'), (0.0052884967869151235, 'Dodge'), (0.0050466499734050123, 'Compact'), (0.004667643753539316, 'premium unleaded (recommended)'), (0.0046389378930114982, 'Plymouth'), (0.0046297715044291794, 'Regular Cab Pickup'), (0.0043293444091571801, 'Midsize'), (0.0035086750525238669, 'Volkswagen'), (0.0033545422880503139, 'front wheel drive'), (0.0026529154557274962, 'Cargo Van'), (0.0024780008382449328, 'Crew Cab Pickup'), (0.0024543705378943185, 'Extended Cab Pickup'), (0.0023874945383657495, 'Chevrolet'), (0.0023228972103178556, 'Sedan'), (0.0021375591717644202, 'Coupe'), (0.0020992318700661975, 'Ford'), (0.0018119403848480045, 'Nissan'), (0.0017257075130051184, 'Passenger Minivan'), (0.0017181551313754883, 'all wheel drive'), (0.0016620563548926126, '4dr Hatchback'), (0.0016596534022751701, 'four wheel drive'), (0.0016515218094791369, 'premium unleaded (required)'), (0.0015939965759999221, 'rear wheel drive'), (0.0014657423770425941, '2dr Hatchback'), (0.0013662273274579141, 'Suzuki'), (0.0012503459615613689, 'Convertible'), (0.0012485957636390774, 'flex-fuel (unleaded/E85)'), (0.0011136390685899109, 'Mazda'), (0.00095988570777368195, 'Pontiac'), (0.00089887048355191635, '10.'), (0.00086628096619850009, 'Mitsubishi'), (0.00085078436889283484, 'Passenger Van'), (0.00084358081524058188, 'Chrysler'), (0.00076963021796586204, 'Wagon'), (0.00071468897572865542, 'FIAT'), (0.00060820915917082915, 'Honda'), (0.00051525362065816789, 'AUTOMATED_MANUAL'), (0.00049190926886432892, 'UNKNOWN'), (0.00042652268490076477, 'DIRECT_DRIVE'), (0.00039146233492913491, 'Subaru'), (0.00035053860770175086, 'diesel'), (0.00034892606079634685, 'flex-fuel (unleaded/natural gas)'), (0.00033488527740295113, '0.'), (0.00026954674182451751, 'Kia'), (0.00023495662187523626, ' 3.'), (0.00022620227371333946, 'electric'), (0.0001758573074035435, 'Hyundai'), (0.00015916143379725772, 'Cargo Minivan'), (9.7964946145945485e-05, 'Scion'), (8.076551671833334e-05, '5.'), (7.0638944753739118e-05, '12.'), (5.5671679699522742e-05, 'natural gas'), (1.3866647278335222e-05, 'Convertible SUV')]\n"
     ]
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "num_attribs = [\"Engine HP\",\"Age\",\"City MPG\",\"Engine HP sq\",\"Engine HP cu\",\"Engine HP fourth\"]\n",
    "categorical_attribs = [  '0.' , ' 3.',   '4.' ,  '5.' ,  '6.',   '8.' , '10.', '12.'] + ['diesel', 'electric' ,'flex-fuel (unleaded/E85)',\n",
    " 'flex-fuel (unleaded/natural gas)' ,'natural gas', 'premium unleaded (recommended)', 'premium unleaded (required)',\n",
    " 'regular unleaded'] + ['AUTOMATED_MANUAL' ,'AUTOMATIC' ,'DIRECT_DRIVE' ,'MANUAL', 'UNKNOWN'] + ['all wheel drive','four wheel drive', 'front wheel drive', 'rear wheel drive'] + ['Compact' ,'Large', 'Midsize']+['2dr Hatchback', '2dr SUV' ,'4dr Hatchback', '4dr SUV', 'Cargo Minivan',\n",
    " 'Cargo Van', 'Convertible', 'Convertible SUV' ,'Coupe', 'Crew Cab Pickup','Extended Cab Pickup' ,'Passenger Minivan' ,'Passenger Van','Regular Cab Pickup', 'Sedan' ,'Wagon']+['Chevrolet', 'Chrysler', 'Dodge', 'FIAT' ,'Ford', 'Honda', 'Hyundai', 'Kia', 'Mazda' ,'Mitsubishi' ,'Nissan', 'Oldsmobile', 'Plymouth', 'Pontiac' ,'Scion', 'Subaru','Suzuki', 'Volkswagen']\n",
    "attributes = num_attribs+categorical_attribs\n",
    "print(sorted(zip(feature_importances, attributes), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the best predictors are City Mile per gallon, Engine HP, Transmission, Age of car, Fuel Type, Size, MAke, Style. We do retain all parameters in the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Final RMSE:2984.82103773\n",
      "predicted prices\n",
      "[ 21986.  22206.  21696.   2001.  27786.]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n",
      "scores: [ 0.11881722  0.10272097  0.10559327  0.11410089  0.11348399  0.11406455\n",
      "  0.11516546  0.11720303  0.10634292  0.1069175 ]\n",
      "mean: 0.111440979849\n",
      "std dev: 0.00525642924658\n",
      "scores: [ 0.18577213  0.14216497  0.13720441  0.1733354   0.18457533  0.2279094\n",
      "  0.1822802   0.14768085  0.17221401  0.15775179]\n",
      "mean: 0.171088849229\n",
      "std dev: 0.0254326093686\n"
     ]
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "final_predictions = final_model.predict(test_X_make)\n",
    "final_mse = mean_squared_error(np.exp(test_Y), np.exp(final_predictions))\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(\"Random Forest Regressor Final RMSE:\"+str(final_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions_make[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))\n",
    "\n",
    "final_model_scores = cross_val_score(final_model,train_X_make,train_Y.values.ravel(),scoring=\"neg_mean_squared_error\",cv=10)\n",
    "final_model_scores = np.sqrt(-final_model_scores)\n",
    "\n",
    "print(\"scores:\",final_model_scores)\n",
    "print(\"mean:\",final_model_scores.mean())\n",
    "print(\"std dev:\",final_model_scores.std())\n",
    "\n",
    "final_model_scores = cross_val_score(final_model,test_X_make,test_Y.values.ravel(),scoring=\"neg_mean_squared_error\",cv=10)\n",
    "final_model_scores = np.sqrt(-final_model_scores)\n",
    "\n",
    "print(\"scores:\",final_model_scores)\n",
    "print(\"mean:\",final_model_scores.mean())\n",
    "print(\"std dev:\",final_model_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the model is fitting quite well, with similar RMSE values in train and test data set. We plot the learning curves for the best model and see the learning curve, by plotting the rmse vs size of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEOCAYAAAB8aOvdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f988d7a898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(model, X, y):\n",
    "    \n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X)):\n",
    "        model.fit(X[:m], y[:m].values.ravel())\n",
    "        y_train_predict = model.predict(X[:m])\n",
    "        y_val_predict = model.predict(test_X_make)\n",
    "        train_errors.append(mean_squared_error(y[:m], y_train_predict))\n",
    "        val_errors.append(mean_squared_error(test_Y, y_val_predict))\n",
    "\n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=14)   \n",
    "    plt.xlabel(\"Training set size\", fontsize=14) \n",
    "    plt.ylabel(\"RMSE\", fontsize=14)   \n",
    "\n",
    "plot_learning_curves(final_model, train_X_make, train_Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net RMSE:8759.33892732\n"
     ]
    }
   ],
   "source": [
    "#We try ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "elastic_net.fit(train_X_make, train_Y)\n",
    "carSales_predictions = elastic_net.predict(test_X_make)\n",
    "elastic_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "elastic_rmse = np.sqrt(elastic_mse)\n",
    "print(\"Elastic Net RMSE:\"+str(elastic_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RMSE:8219.89519774\n"
     ]
    }
   ],
   "source": [
    "#We try Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg = Ridge(alpha=1, solver=\"cholesky\", random_state=42)\n",
    "ridge_reg.fit(train_X_make, train_Y)\n",
    "carSales_predictions = ridge_reg.predict(test_X_make)\n",
    "ridge_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "ridge_rmse = np.sqrt(ridge_mse)\n",
    "print(\"Ridge RMSE:\"+str(ridge_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso RMSE:8817.30365561\n"
     ]
    }
   ],
   "source": [
    "#We try Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "lasso_reg.fit(train_X_make, train_Y)\n",
    "carSales_predictions = lasso_reg.predict(test_X_make)\n",
    "lasso_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "lasso_rmse = np.sqrt(lasso_mse)\n",
    "print(\"Lasso RMSE:\"+str(lasso_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find these give worse results. \n",
    "We use GradientBoostingRegressor from sklearn finally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor RMSE:3246.28768199\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=8, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(train_X_make, train_Y.values.ravel())\n",
    "carSales_predictions = gbrt.predict(test_X_make)\n",
    "gbrt_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "gbrt_rmse = np.sqrt(gbrt_mse)\n",
    "print(\"Gradient Boosting Regressor RMSE:\"+str(gbrt_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor SLOW RMSE:3135.18562065\n"
     ]
    }
   ],
   "source": [
    "gbrt_slow = GradientBoostingRegressor(max_depth=30, n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "gbrt_slow.fit(train_X_make, train_Y.values.ravel())\n",
    "carSales_predictions = gbrt_slow.predict(test_X_make)\n",
    "gbrt_slow_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "gbrt_slow_rmse = np.sqrt(gbrt_slow_mse)\n",
    "print(\"Gradient Boosting Regressor SLOW RMSE:\"+str(gbrt_slow_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMETERS FOR GRADIENT BOOSTING REGRESSOR IS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20, 'n_estimators': 100}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    # try 2 (2×2) combinations of hyperparameters\n",
    "    {'n_estimators': [100,200], 'max_depth': [20, 30]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    #{'bootstrap': [False], 'n_estimators': [100,200], 'max_depth': [20, 30, 40]},\n",
    "  ]\n",
    "\n",
    "gbrt_reg = GradientBoostingRegressor(random_state=42, learning_rate=0.1)\n",
    "# train across 5 folds, that's a total of (4)*5=20 rounds of training \n",
    "grid_search_gbrt = GridSearchCV(gbrt_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search_gbrt.fit(train_X_make, train_Y.values.ravel())\n",
    "print(\"BEST PARAMETERS FOR GRADIENT BOOSTING REGRESSOR IS:\")\n",
    "grid_search_gbrt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor BEST RMSE:3100.46980326\n"
     ]
    }
   ],
   "source": [
    "gbrt_slow = GradientBoostingRegressor(max_depth=20, n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gbrt_slow.fit(train_X_make, train_Y.values.ravel())\n",
    "carSales_predictions = gbrt_slow.predict(test_X_make)\n",
    "gbrt_slow_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "gbrt_slow_rmse = np.sqrt(gbrt_slow_mse)\n",
    "print(\"Gradient Boosting Regressor BEST RMSE:\"+str(gbrt_slow_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the best fit is given by RandomForestRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try Deep Learning technique and compare the RMSE. We use keras with tensorflow backend and then repeat the same expt with cntk backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                3450      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 5,011\n",
      "Trainable params: 5,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#We use two hidden layers with 50 and 30 units with Relu activation, and no activation in the output layer, since \n",
    "#we want to predict the car price.\n",
    "model.add(Dense(50,input_dim=(train_X_make.shape[1]),activation='relu'))\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myOptimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer=myOptimizer, metrics=['mse'])\n",
    "history = model.fit(train_X_make, train_Y, epochs=200,  validation_data=(test_X_make,test_Y), batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRETKKCmIiEiZ/wfFqijWa0IllQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1edb3bd38d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], color = 'blue')\n",
    "plt.plot(history.history['val_loss'], color=  'red')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learing RMSE with two hidden layers:3095.1247291\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = model.predict(test_X_make)\n",
    "dl_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "dl_rmse = np.sqrt(dl_mse)\n",
    "print(\"Deep Learing RMSE with two hidden layers:\"+str(dl_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try 3 hidden layers and attempt to fit the problem better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 50)                3450      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,691\n",
      "Trainable params: 4,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50,input_dim=(train_X_make.shape[1]),activation='relu'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myOptimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer=myOptimizer, metrics=['mse'])\n",
    "history = model.fit(train_X_make, train_Y, epochs=300,  validation_data=(test_X_make,test_Y), batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learing RMSE with three hidden layers:2994.02613942\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = model.predict(test_X_make)\n",
    "dl_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "dl_rmse = np.sqrt(dl_mse)\n",
    "print(\"Deep Learing RMSE with three hidden layers:\"+str(dl_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "We find the performance of Deep Learning with 3 hidden layers is equivalent to that of RandomForestRegressor in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 20)                1320      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,341\n",
      "Trainable params: 1,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20,input_dim=(train_X_make.shape[1]),activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myOptimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer=myOptimizer, metrics=['mse'])\n",
    "history = model.fit(train_X_make, train_Y, epochs=200,  validation_data=(test_X_make,test_Y), batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learing RMSE with one hidden layer:3934.8550403\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = model.predict(test_X_make)\n",
    "dl_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "dl_rmse = np.sqrt(dl_mse)\n",
    "print(\"Deep Learing RMSE with one hidden layer:\"+str(dl_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude three hidden layers configuration is the best so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try XGBRegressor, a latest technique. We start by default setting and then use best parameter for n_estimator by trying number of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor() \n",
    "xgb_model.fit(train_X_make, train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE:3439.22116197\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = xgb_model.predict(test_X_make)\n",
    "xgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"XGB RMSE:\"+str(xgb_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=350,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=350) \n",
    "xgb_model.fit(train_X_make, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE, with n_estmators=350:2824.93254803\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = xgb_model.predict(test_X_make)\n",
    "xgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"XGB RMSE, with n_estmators=350:\"+str(xgb_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=350,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=350, max_depth=5) \n",
    "xgb_model.fit(train_X_make, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE, with n_estmators=350,max_depth=5:2645.05876051\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = xgb_model.predict(test_X_make)\n",
    "xgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"XGB RMSE, with n_estmators=350,max_depth=5:\"+str(xgb_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=10, min_child_weight=1, missing=None, n_estimators=350,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=350, max_depth=10) \n",
    "xgb_model.fit(train_X_make, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE, with n_estmators=350,max_depth=10:2956.00660994\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = xgb_model.predict(test_X_make)\n",
    "xgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"XGB RMSE, with n_estmators=350,max_depth=10:\"+str(xgb_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude the setting of n_estimators=350 and max_depth=5 works best in this case, and this model is the best amongst all the models compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate and display feature importances from the XGBoost model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.47287929e-01   1.90432623e-01   1.20507121e-01   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.09737292e-03   1.30701868e-04\n",
      "   2.48333556e-03   2.87544122e-03   4.18245979e-03   2.87544122e-03\n",
      "   3.92105617e-03   0.00000000e+00   3.00614303e-03   0.00000000e+00\n",
      "   1.07175531e-02   1.82982616e-03   4.70526749e-03   7.31930463e-03\n",
      "   6.92719920e-03   5.88158425e-03   3.13684484e-03   1.68605410e-02\n",
      "   0.00000000e+00   8.10351595e-03   1.82982616e-03   8.36491957e-03\n",
      "   1.55535229e-02   8.49562138e-03   6.79649739e-03   2.19579134e-02\n",
      "   1.41158020e-02   1.00640440e-02   1.20245721e-02   2.22193170e-03\n",
      "   9.14913043e-03   1.47693111e-02   5.35877654e-03   4.18245979e-03\n",
      "   1.12403603e-02   4.96667111e-03   9.67193861e-03   7.31930463e-03\n",
      "   9.41053499e-03   8.75702500e-03   3.00614303e-03   5.09737292e-03\n",
      "   1.21552739e-02   6.27368968e-03   1.62070319e-02   4.18245979e-03\n",
      "   7.97281414e-03   2.87544122e-03   1.32008884e-02   7.31930463e-03\n",
      "   6.14298787e-03   8.88772681e-03   7.58070825e-03   1.33315902e-02\n",
      "   1.33315902e-02   3.26754665e-03   6.14298787e-03   6.92719920e-03\n",
      "   2.35263375e-03   3.13684484e-03   4.05175798e-03   1.20245721e-02]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUkMMfUlqyP8B1d72WnbsYPMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1edb9b093c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=350, max_depth=5) \n",
    "xgb_model.fit(train_X_make, train_Y)\n",
    "print(xgb_model.feature_importances_)\n",
    "# plot\n",
    "plt.bar(range(len(xgb_model.feature_importances_)), xgb_model.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the numerical features, Engine HP, Age, City MPG has the highest importances, followed by categorical features. Among the categorical\n",
    "features we find the Engine Cylinder, and Engine Fuel Type has lease importance. Transmission type, and Size, and Make have high importances. We drop the Engine Cylinder from Train and Test data and fit our model again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall the order of Categorical variables is : \n",
    "      [ 0.  3.  4.  5.  6.  8. 10. 12.]\n",
    "['diesel' 'electric' 'flex-fuel (unleaded/E85)'\n",
    " 'flex-fuel (unleaded/natural gas)' 'natural gas'\n",
    " 'premium unleaded (recommended)' 'premium unleaded (required)'\n",
    " 'regular unleaded']\n",
    "['AUTOMATED_MANUAL' 'AUTOMATIC' 'DIRECT_DRIVE' 'MANUAL' 'UNKNOWN']\n",
    "['all wheel drive' 'four wheel drive' 'front wheel drive'\n",
    " 'rear wheel drive']\n",
    "['Compact' 'Large' 'Midsize']\n",
    "['Chevrolet' 'Chrysler' 'Dodge' 'FIAT' 'Ford' 'Honda' 'Hyundai' 'Kia'\n",
    " 'Mazda' 'Mitsubishi' 'Nissan' 'Oldsmobile' 'Plymouth' 'Pontiac' 'Scion'\n",
    " 'Subaru' 'Suzuki' 'Volkswagen']\n",
    "['2dr Hatchback' '2dr SUV' '4dr Hatchback' '4dr SUV' 'Cargo Minivan'\n",
    " 'Cargo Van' 'Convertible' 'Convertible SUV' 'Coupe' 'Crew Cab Pickup'\n",
    " 'Extended Cab Pickup' 'Passenger Minivan' 'Passenger Van'\n",
    " 'Regular Cab Pickup' 'Sedan' 'Wagon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(train_X_make.shape[1])\n",
    "train_X_make_upd = np.delete(train_X_make,[7,8,9,10,11,12,13,14],1) # we drop the 8 columns after the first 6 numeric ones\n",
    "print(train_X_make_upd.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X_make_upd = np.delete(test_X_make,[7,8,9,10,11,12,13,14],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=350, max_depth=5) \n",
    "xgb_model.fit(train_X_make_upd, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE, with n_estmators=350,max_depth=5:2654.449678884159\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = xgb_model.predict(test_X_make_upd)\n",
    "xgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"XGB RMSE, with n_estmators=350,max_depth=5:\"+str(xgb_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find removing the Engine cylinder categorical variable, does not have any effect on the model. We now try removing the Engine fuel type categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(train_X_make.shape[1])\n",
    "train_X_make_upd1 = np.delete(train_X_make,[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],1) # we drop the 8 columns after the first 3 numeric ones\n",
    "print(train_X_make_upd1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X_make_upd1 = np.delete(test_X_make,[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=350,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=350, max_depth=5) \n",
    "xgb_model.fit(train_X_make_upd1, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE, with n_estmators=350,max_depth=5:2698.455288123365\n",
      "predicted prices\n",
      "[21821.773  23767.822  20159.508   1966.6238 26621.643 ]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = xgb_model.predict(test_X_make_upd1)\n",
    "xgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"XGB RMSE, with n_estmators=350,max_depth=5:\"+str(xgb_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "We find removing the Engine Fuel type categorical variable, does have a small effect on the model. \n",
    "We decide to drop the Engine Cylinder, based on this analysis from our original set of parameters.\n",
    "So our final model has the numerical parameters : Engine HP, Age of Car, log City MPG\n",
    "and the categorical parameters : Engine Fuel Type,Transmission Type, Driven Wheels, Vehicle Size, Vehicle Style and Make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model to file\n",
    "pickle.dump(xgb_model, open(\"C:/users/hackuser1/carsales_xgb.pickle.dat\", \"wb\"))\n",
    "\n",
    "\n",
    "# load model from file\n",
    "#loaded_model = pickle.load(open(\"C:/users/hackuser1/carsales_xgb.pickle.dat\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
