{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook is to explore various prediction models from the Used Car Price data \n",
    "at : https://www.kaggle.com/CooperUnion/cardataset\n",
    "Various Regression techniques are explored, with K-fold cross validation, grid search of parameters, including \n",
    "Deep Learning techniques and the best approach is selected based on Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import all necessary libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense   \n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Read the pre-processed pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5556, 47)\n",
      "(5556, 65)\n"
     ]
    }
   ],
   "source": [
    "train_X=pd.read_pickle('C:/users/hackuser1/Hackathon18/train_X_ord.pkl')\n",
    "test_X=pd.read_pickle('C:/users/hackuser1/Hackathon18/test_X_ord.pkl')\n",
    "train_Y=pd.read_pickle('C:/users/hackuser1/Hackathon18/train_Y_ord.pkl') # train Y with log(MSRP)\n",
    "test_Y=pd.read_pickle('C:/users/hackuser1/Hackathon18/test_Y_ord.pkl')\n",
    "train_Y_orig=pd.read_pickle('C:/users/hackuser1/Hackathon18/train_Y_ord_orig.pkl') # train Y with MSRP unmodified\n",
    "test_Y_orig=pd.read_pickle('C:/users/hackuser1/Hackathon18/test_Y_ord_orig.pkl')\n",
    "\n",
    "train_X_make=pd.read_pickle('C:/users/hackuser1/Hackathon18/train_X_ord_make.pkl')\n",
    "test_X_make=pd.read_pickle('C:/users/hackuser1/Hackathon18/test_X_ord_make.pkl')\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_X_make.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit Sklearn LinearRegression and use this to make predictions on the test data and check the RMSE\n",
    "Use train X data with make and without make, and Test Y as MSRP as well as Log MSRP and compare the RMSE values on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit train data without make info, and log MSRP\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(train_X, train_Y)\n",
    "\n",
    "#fit train data without make and MSRP, as it\n",
    "lin_reg_1 = LinearRegression()\n",
    "lin_reg_1.fit(train_X, train_Y_orig)\n",
    "\n",
    "#fit train data with make and log MSRP\n",
    "lin_reg_make = LinearRegression()\n",
    "lin_reg_make.fit(train_X_make, train_Y)\n",
    "\n",
    "#fit train data with make and MSRP, as it\n",
    "lin_reg_make1 = LinearRegression()\n",
    "lin_reg_make1.fit(train_X_make, train_Y_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse without make, log MSRP:8663.24767682\n",
      "rmse without make, MSRP, as is:28097.4411188\n",
      "rmse with make, log MSRP:8298.81451967\n",
      "rmse with make, MSRP, as is:28055.9651761\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = lin_reg.predict(test_X)\n",
    "lin_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"rmse without make, log MSRP:\"+str(lin_rmse))\n",
    "\n",
    "carSales_predictions = lin_reg_1.predict(test_X)\n",
    "lin_mse = mean_squared_error(test_Y, carSales_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"rmse without make, MSRP, as is:\"+str(lin_rmse))\n",
    "\n",
    "carSales_predictions = lin_reg_make.predict(test_X_make)\n",
    "lin_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"rmse with make, log MSRP:\"+str(lin_rmse))\n",
    "\n",
    "carSales_predictions = lin_reg_make1.predict(test_X_make)\n",
    "lin_mse = mean_squared_error(test_Y, carSales_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"rmse with make, MSRP, as is:\"+str(lin_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We observe the data with make and log MSRP gives best results. We use this data to fit subsequent algorithms.\n",
    "Next we use SGDRegressor from scikit learn and compare the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', max_iter=500, n_iter=None, penalty=None,\n",
       "       power_t=0.25, random_state=None, shuffle=True, tol=None, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_reg_make = SGDRegressor(max_iter=500,penalty=None,eta0=0.01)\n",
    "sgd_reg_make.fit(train_X_make, train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD RMSE:8471.19867171\n",
      "predicted prices\n",
      "[ 10436.35938607  23874.66237829  12297.32990036   4129.98480997\n",
      "  26121.45349847]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions_make = sgd_reg_make.predict(test_X_make)\n",
    "sgd_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions_make))\n",
    "sgd_rmse = np.sqrt(sgd_mse)\n",
    "print(\"SGD RMSE:\"+str(sgd_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions_make[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(train_X,train_Y)\n",
    "\n",
    "tree_reg_make = DecisionTreeRegressor()\n",
    "tree_reg_make.fit(train_X_make,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE, without make:3195.07325153\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = tree_reg.predict(test_X)\n",
    "tree_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(\"Decision Tree RMSE, without make:\"+str(tree_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE, with make:3110.74905826\n",
      "predicted prices\n",
      "[ 21986.  22206.  21696.   2001.  27786.]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions_make = tree_reg_make.predict(test_X_make)\n",
    "tree_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions_make))\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(\"Decision Tree RMSE, with make:\"+str(tree_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions_make[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find Decision tree with make data included reduces the RMSE and is the best so far. We \n",
    "validate this using K-fold Cross validation with k set to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [ 0.11743598  0.11099468  0.10167762  0.11095131  0.10396001  0.10785319\n",
      "  0.10309168  0.1107515   0.10710575  0.10429869]\n",
      "mean: 0.107812039723\n",
      "std dev: 0.00456990247701\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(tree_reg_make,train_X_make,train_Y,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\"scores:\",tree_rmse_scores)\n",
    "print(\"mean:\",tree_rmse_scores.mean())\n",
    "print(\"std dev:\",tree_rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows there is a good fit, and there is very less variation between the folds and the data is dependable.\n",
    "We now try RandomForestRegressor, with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg_make = RandomForestRegressor()\n",
    "forest_reg_make.fit(train_X_make,train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor RMSE, with make:3006.58980928\n",
      "predicted prices\n",
      "[ 21986.  22206.  21696.   2001.  27786.]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = forest_reg_make.predict(test_X_make)\n",
    "forest_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print(\"Random Forest Regressor RMSE, with make:\"+str(forest_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions_make[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly a better fit compared to DecisionTree, and we validate this with k-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [ 0.10193718  0.10150114  0.09442559  0.10182752  0.09229687  0.09830095\n",
      "  0.10000251  0.10201605  0.09789777  0.09280072]\n",
      "mean: 0.0983006293765\n",
      "std dev: 0.00366169231293\n"
     ]
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest_reg_make,train_X_make,train_Y.values.ravel(),scoring=\"neg_mean_squared_error\",cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "\n",
    "print(\"scores:\",forest_rmse_scores)\n",
    "print(\"mean:\",forest_rmse_scores.mean())\n",
    "print(\"std dev:\",forest_rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use GridSearch to find the optimum parameters for RandomForestRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMETERS FOR RANDOM FOREST REGRESSOR IS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'n_estimators': 30}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(train_X_make, train_Y.values.ravel())\n",
    "print(\"BEST PARAMETERS FOR RANDOM FOREST REGRESSOR IS:\")\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=30, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit using best parameters and check\n",
    "forest_reg_make = RandomForestRegressor(max_features=8,n_estimators=30)\n",
    "forest_reg_make.fit(train_X_make,train_Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor RMSE, with make:3060.57084897\n",
      "predicted prices\n",
      "[ 21986.  22206.  21696.   2001.  27786.]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = forest_reg_make.predict(test_X_make)\n",
    "forest_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print(\"Random Forest Regressor RMSE, with make:\"+str(forest_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions_make[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observation is : Default parameters gives better results.\n",
    "We now find the feature importances from the GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.51222971167234455, 'City MPG'), (0.14792201802189073, 'Engine HP'), (0.040567461767208476, 'AUTOMATIC'), (0.032248768541910007, 'Age'), (0.030703906424741613, 'regular unleaded'), (0.02564030029001552, 'MANUAL'), (0.019372873771421838, 'premium unleaded (recommended)'), (0.015558711475096552, 'Large'), (0.015126838516752013, 'Oldsmobile'), (0.010921668085859251, 'Regular Cab Pickup'), (0.010570801867184867, '8.'), (0.0094306698937316261, 'Plymouth'), (0.0084518531088829275, '4dr SUV'), (0.0074293416542418229, 'Compact'), (0.0064167390653077352, 'Midsize'), (0.0060953032209234278, 'front wheel drive'), (0.0060922616387048423, 'Dodge'), (0.0059768123568712085, '6.'), (0.005647578826506937, 'premium unleaded (required)'), (0.0050926855022228445, '2dr SUV'), (0.0050496014540356727, 'four wheel drive'), (0.0045749585336413113, 'rear wheel drive'), (0.0044071707266135681, 'Crew Cab Pickup'), (0.0042983794471047132, '4.'), (0.0042692483329895255, 'Extended Cab Pickup'), (0.0038999598721438256, '2dr Hatchback'), (0.0034013727902103526, 'Volkswagen'), (0.003357296842133181, 'Cargo Van'), (0.0032482803975619886, 'all wheel drive'), (0.0031001863614168804, 'Nissan'), (0.0030561128925689898, '4dr Hatchback'), (0.0029217412247848113, 'Passenger Minivan'), (0.002819490735166397, 'Chevrolet'), (0.0027893897584574784, 'Ford'), (0.0025557700363205583, 'Convertible'), (0.0023558042700243592, 'flex-fuel (unleaded/E85)'), (0.0022351025174372286, 'Coupe'), (0.0020097766940541249, 'Sedan'), (0.0016242781025624996, 'Suzuki'), (0.001623566697819178, 'Mazda'), (0.0015425449711954631, 'diesel'), (0.0014157265601677446, '10.'), (0.0013142339059312061, 'Subaru'), (0.0012732776919034182, 'Pontiac'), (0.00097825050326376959, 'Mitsubishi'), (0.00096346489454685004, 'Hyundai'), (0.00091392330178694599, 'Wagon'), (0.00088788096350143442, 'AUTOMATED_MANUAL'), (0.00074808456393650371, '0.'), (0.00074726315433327876, 'Passenger Van'), (0.00067519475473970915, 'Chrysler'), (0.00063998177163859392, 'Honda'), (0.00059970628655754915, 'UNKNOWN'), (0.00042264828587880649, 'FIAT'), (0.00037880260592084981, 'Cargo Minivan'), (0.00030664831829765594, '5.'), (0.00030506724491894267, ' 3.'), (0.0002990499200805492, 'Kia'), (0.00013546977922986674, 'electric'), (9.5532517800993617e-05, '12.'), (9.5523563514710928e-05, 'DIRECT_DRIVE'), (8.9937447692454238e-05, 'Scion'), (5.8898898820218819e-05, 'Convertible SUV'), (1.5465375615319527e-05, 'flex-fuel (unleaded/natural gas)'), (3.6293298617563961e-06, 'natural gas')]\n"
     ]
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "num_attribs = [\"Engine HP\",\"City MPG\",\"Age\"]\n",
    "categorical_attribs = [  '0.' , ' 3.',   '4.' ,  '5.' ,  '6.',   '8.' , '10.', '12.'] + ['diesel', 'electric' ,'flex-fuel (unleaded/E85)',\n",
    " 'flex-fuel (unleaded/natural gas)' ,'natural gas', 'premium unleaded (recommended)', 'premium unleaded (required)',\n",
    " 'regular unleaded'] + ['AUTOMATED_MANUAL' ,'AUTOMATIC' ,'DIRECT_DRIVE' ,'MANUAL', 'UNKNOWN'] + ['all wheel drive','four wheel drive', 'front wheel drive', 'rear wheel drive'] + ['Compact' ,'Large', 'Midsize']+['2dr Hatchback', '2dr SUV' ,'4dr Hatchback', '4dr SUV', 'Cargo Minivan',\n",
    " 'Cargo Van', 'Convertible', 'Convertible SUV' ,'Coupe', 'Crew Cab Pickup','Extended Cab Pickup' ,'Passenger Minivan' ,'Passenger Van','Regular Cab Pickup', 'Sedan' ,'Wagon']+['Chevrolet', 'Chrysler', 'Dodge', 'FIAT' ,'Ford', 'Honda', 'Hyundai', 'Kia', 'Mazda' ,'Mitsubishi' ,'Nissan', 'Oldsmobile', 'Plymouth', 'Pontiac' ,'Scion', 'Subaru','Suzuki', 'Volkswagen']\n",
    "attributes = num_attribs+categorical_attribs\n",
    "print(sorted(zip(feature_importances, attributes), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the best predictors are City Mile per gallon, Engine HP, Transmission, Age of car, Fuel Type, Size, MAke, Style. We do retain all parameters in the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Final RMSE:3040.3607784\n",
      "predicted prices\n",
      "[ 21986.  22206.  21696.   2001.  27786.]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n",
      "scores: [ 0.11199449  0.10856914  0.11540133  0.11024884  0.10283988  0.12166811\n",
      "  0.11216988  0.12351604  0.10642059  0.12219071]\n",
      "mean: 0.113501900189\n",
      "std dev: 0.00669968418204\n",
      "scores: [ 0.16044081  0.1181285   0.1467781   0.16295343  0.15222958  0.16306924\n",
      "  0.16020828  0.12874094  0.19367385  0.15581878]\n",
      "mean: 0.154204150659\n",
      "std dev: 0.019492107897\n"
     ]
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "final_predictions = final_model.predict(test_X_make)\n",
    "final_mse = mean_squared_error(np.exp(test_Y), np.exp(final_predictions))\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(\"Random Forest Regressor Final RMSE:\"+str(final_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions_make[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))\n",
    "\n",
    "final_model_scores = cross_val_score(final_model,train_X_make,train_Y.values.ravel(),scoring=\"neg_mean_squared_error\",cv=10)\n",
    "final_model_scores = np.sqrt(-final_model_scores)\n",
    "\n",
    "print(\"scores:\",final_model_scores)\n",
    "print(\"mean:\",final_model_scores.mean())\n",
    "print(\"std dev:\",final_model_scores.std())\n",
    "\n",
    "final_model_scores = cross_val_score(final_model,test_X_make,test_Y.values.ravel(),scoring=\"neg_mean_squared_error\",cv=10)\n",
    "final_model_scores = np.sqrt(-final_model_scores)\n",
    "\n",
    "print(\"scores:\",final_model_scores)\n",
    "print(\"mean:\",final_model_scores.mean())\n",
    "print(\"std dev:\",final_model_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the model is fitting quite well, with similar RMSE values in train and test data set. We plot the learning curves for the best model and see the learning curve, by plotting the rmse vs size of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEOCAYAAAB8aOvdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f988d7a898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(model, X, y):\n",
    "    \n",
    "    train_errors, val_errors = [], []\n",
    "    for m in range(1, len(X)):\n",
    "        model.fit(X[:m], y[:m].values.ravel())\n",
    "        y_train_predict = model.predict(X[:m])\n",
    "        y_val_predict = model.predict(test_X_make)\n",
    "        train_errors.append(mean_squared_error(y[:m], y_train_predict))\n",
    "        val_errors.append(mean_squared_error(test_Y, y_val_predict))\n",
    "\n",
    "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=14)   \n",
    "    plt.xlabel(\"Training set size\", fontsize=14) \n",
    "    plt.ylabel(\"RMSE\", fontsize=14)   \n",
    "\n",
    "plot_learning_curves(final_model, train_X_make, train_Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net RMSE:8777.11146489\n"
     ]
    }
   ],
   "source": [
    "#We try ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "elastic_net.fit(train_X_make, train_Y)\n",
    "carSales_predictions = elastic_net.predict(test_X_make)\n",
    "elastic_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "elastic_rmse = np.sqrt(elastic_mse)\n",
    "print(\"Elastic Net RMSE:\"+str(elastic_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RMSE:8268.07759323\n"
     ]
    }
   ],
   "source": [
    "#We try Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg = Ridge(alpha=1, solver=\"cholesky\", random_state=42)\n",
    "ridge_reg.fit(train_X_make, train_Y)\n",
    "carSales_predictions = ridge_reg.predict(test_X_make)\n",
    "ridge_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "ridge_rmse = np.sqrt(ridge_mse)\n",
    "print(\"Ridge RMSE:\"+str(ridge_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso RMSE:8697.20098706\n"
     ]
    }
   ],
   "source": [
    "#We try Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "lasso_reg.fit(train_X_make, train_Y)\n",
    "carSales_predictions = lasso_reg.predict(test_X_make)\n",
    "lasso_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "lasso_rmse = np.sqrt(lasso_mse)\n",
    "print(\"Lasso RMSE:\"+str(lasso_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find these give worse results. \n",
    "We use GradientBoostingRegressor from sklearn finally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor RMSE:3293.94301909\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=8, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(train_X_make, train_Y.values.ravel())\n",
    "carSales_predictions = gbrt.predict(test_X_make)\n",
    "gbrt_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "gbrt_rmse = np.sqrt(gbrt_mse)\n",
    "print(\"Gradient Boosting Regressor RMSE:\"+str(gbrt_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor SLOW RMSE:3111.99605211\n"
     ]
    }
   ],
   "source": [
    "gbrt_slow = GradientBoostingRegressor(max_depth=30, n_estimators=200, learning_rate=0.1, random_state=42)\n",
    "gbrt_slow.fit(train_X_make, train_Y.values.ravel())\n",
    "carSales_predictions = gbrt_slow.predict(test_X_make)\n",
    "gbrt_slow_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "gbrt_slow_rmse = np.sqrt(gbrt_slow_mse)\n",
    "print(\"Gradient Boosting Regressor SLOW RMSE:\"+str(gbrt_slow_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [100, 200, 300], 'max_depth': [20, 30, 40]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    #{'bootstrap': [False], 'n_estimators': [100,200], 'max_depth': [20, 30, 40]},\n",
    "  ]\n",
    "\n",
    "gbrt_reg = GradientBoostingRegressor(random_state=42, learning_rate=0.1)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search_gbrt = GridSearchCV(gbrt_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search_gbrt.fit(train_X_make, train_Y.values.ravel())\n",
    "print(\"BEST PARAMETERS FOR GRADIENT BOOSTING REGRESSOR IS:\")\n",
    "grid_search_gbrt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the best fit is given by RandomForestRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try Deep Learning technique and compare the RMSE. We use keras with tensorflow backend and then repeat the same expt with cntk backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                3300      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 4,861\n",
      "Trainable params: 4,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#We use two hidden layers with 50 and 30 units with Relu activation, and no activation in the output layer, since \n",
    "#we want to predict the car price.\n",
    "model.add(Dense(50,input_dim=(train_X_make.shape[1]),activation='relu'))\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myOptimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer=myOptimizer, metrics=['mse'])\n",
    "history = model.fit(train_X_make, train_Y, epochs=200,  validation_data=(test_X_make,test_Y), batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUBARkSiFgoiIRCkUREQk6v8DKnoiNKNmvXIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x259e5b65400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], color = 'blue')\n",
    "plt.plot(history.history['val_loss'], color=  'red')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learing RMSE with two hidden layers:3490.4683134\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = model.predict(test_X_make)\n",
    "dl_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "dl_rmse = np.sqrt(dl_mse)\n",
    "print(\"Deep Learing RMSE with two hidden layers:\"+str(dl_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the same with backend as cntk, we change backend=\"cntk\" in keras.json and rerun the expt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4624.50567544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\cntk\\core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input4\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = model.predict(test_X_make)\n",
    "dl_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "dl_rmse = np.sqrt(dl_mse)\n",
    "print(dl_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try different parameters of Deep Learning to fit the problem better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 50)                3300      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,541\n",
      "Trainable params: 4,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50,input_dim=(train_X_make.shape[1]),activation='relu'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myOptimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer=myOptimizer, metrics=['mse'])\n",
    "history = model.fit(train_X_make, train_Y, epochs=300,  validation_data=(test_X_make,test_Y), batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learing RMSE with three hidden layers:2748.39994063\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = model.predict(test_X_make)\n",
    "dl_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "dl_rmse = np.sqrt(dl_mse)\n",
    "print(\"Deep Learing RMSE with three hidden layers:\"+str(dl_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 20)                1320      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,341\n",
      "Trainable params: 1,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20,input_dim=(train_X_make.shape[1]),activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myOptimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer=myOptimizer, metrics=['mse'])\n",
    "history = model.fit(train_X_make, train_Y, epochs=200,  validation_data=(test_X_make,test_Y), batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learing RMSE with one hidden layer:3934.8550403\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = model.predict(test_X_make)\n",
    "dl_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "dl_rmse = np.sqrt(dl_mse)\n",
    "print(\"Deep Learing RMSE with one hidden layer:\"+str(dl_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude three hidden layers configuration is the best so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try XGBRegressor, a latest technique. We start by default setting and then use best parameter for n_estimator by trying number of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor() \n",
    "xgb_model.fit(train_X_make, train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE:3393.44100697\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = xgb_model.predict(test_X_make)\n",
    "xgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"XGB RMSE:\"+str(xgb_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=350,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=350) \n",
    "xgb_model.fit(train_X_make, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE, with n_estmators=350:2833.7119292\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = xgb_model.predict(test_X_make)\n",
    "xgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"XGB RMSE, with n_estmators=350:\"+str(xgb_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=350,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=350, max_depth=5) \n",
    "xgb_model.fit(train_X_make, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE, with n_estmators=350,max_depth=5:2667.5184859\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = xgb_model.predict(test_X_make)\n",
    "xgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"XGB RMSE, with n_estmators=350,max_depth=5:\"+str(xgb_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=10, min_child_weight=1, missing=None, n_estimators=350,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=350, max_depth=10) \n",
    "xgb_model.fit(train_X_make, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE, with n_estmators=350,max_depth=10:2991.35951284\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = xgb_model.predict(test_X_make)\n",
    "xgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"XGB RMSE, with n_estmators=350,max_depth=10:\"+str(xgb_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude the setting of n_estimators=350 and max_depth=5 works best in this case, and this model is the best amongst all the models compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate and display feature importances from the XGBoost model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.43807226e-01   2.83265948e-01   1.46350861e-01   1.27794407e-03\n",
      "   1.75060832e-05   3.43119237e-03   8.75304162e-04   3.99138685e-03\n",
      "   1.13789539e-03   4.02639911e-04   3.50121663e-05   9.97846713e-04\n",
      "   0.00000000e+00   5.74199529e-03   6.82737271e-04   1.01535278e-03\n",
      "   4.90170345e-03   2.92351586e-03   3.88635043e-03   5.26933093e-03\n",
      "   3.17560360e-02   5.25182513e-05   6.96742116e-03   1.75060835e-04\n",
      "   1.40573848e-02   1.71209499e-02   5.37436781e-03   6.51226286e-03\n",
      "   1.41624212e-02   7.42257945e-03   5.14678843e-03   8.59548710e-03\n",
      "   1.59305357e-03   1.15365088e-02   1.07662417e-02   2.66092457e-03\n",
      "   1.08537718e-03   8.10531620e-03   1.45300489e-03   8.66551138e-03\n",
      "   6.47725072e-03   8.14032834e-03   3.43119237e-03   1.17290753e-03\n",
      "   3.23862536e-03   1.48801710e-02   4.91920952e-03   1.11163631e-02\n",
      "   3.95637471e-03   5.63695887e-03   1.03285897e-03   9.31323599e-03\n",
      "   2.52087601e-03   6.56478107e-03   5.88204386e-03   6.21465966e-03\n",
      "   6.37221429e-03   6.21465966e-03   2.66092457e-03   1.59305357e-03\n",
      "   6.10962324e-03   1.80312654e-03   1.57554750e-03   2.95852800e-03\n",
      "   2.99354014e-03]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x259e7cbc4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(xgb_model.feature_importances_)\n",
    "# plot\n",
    "plt.bar(range(len(xgb_model.feature_importances_)), xgb_model.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the numerical features, Engine HP, Age, City MPG has the highest importances, followed by categorical features. Among the categorical\n",
    "features we find the Transmission type, and Size, and Make have high importances. We drop the Engine Cylinder from Train and Test data and fit our model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "print(train_X_make.shape[1])\n",
    "train_X_make_upd = np.delete(train_X_make,[4,5,6,7,8,9,10,11],1) # we drop the 8 columns after the first 3 numeric ones\n",
    "print(train_X_make_upd.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X_make_upd = np.delete(test_X_make,[4,5,6,7,8,9,10,11],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=350,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=350, max_depth=5) \n",
    "xgb_model.fit(train_X_make_upd, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE, with n_estmators=350,max_depth=5:2683.96022928\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = xgb_model.predict(test_X_make_upd)\n",
    "xgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"XGB RMSE, with n_estmators=350,max_depth=5:\"+str(xgb_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find removing the Engine cylinder categorical variable, does not have any effect on the model. We now try removing the Engine fuel type categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(train_X_make.shape[1])\n",
    "train_X_make_upd1 = np.delete(train_X_make,[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],1) # we drop the 8 columns after the first 3 numeric ones\n",
    "print(train_X_make_upd1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X_make_upd1 = np.delete(test_X_make,[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=350,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=350, max_depth=5) \n",
    "xgb_model.fit(train_X_make_upd1, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE, with n_estmators=350,max_depth=5:2682.05169176\n",
      "predicted prices\n",
      "[ 21703.92773438  23602.3671875   20006.84179688   1944.84020996\n",
      "  26475.63085938]\n",
      "actual prices\n",
      "         0\n",
      "0  23086.0\n",
      "1  25581.0\n",
      "2  19396.0\n",
      "3   2001.0\n",
      "4  24786.0\n"
     ]
    }
   ],
   "source": [
    "carSales_predictions = xgb_model.predict(test_X_make_upd1)\n",
    "xgb_mse = mean_squared_error(np.exp(test_Y), np.exp(carSales_predictions))\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "print(\"XGB RMSE, with n_estmators=350,max_depth=5:\"+str(xgb_rmse))\n",
    "print(\"predicted prices\")\n",
    "print(np.exp(carSales_predictions[0:5]))\n",
    "print(\"actual prices\")\n",
    "print(np.exp(test_Y[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "We find removing the Engine cylinder and Fuel type categorical variables, does not have any effect on the model. \n",
    "We decide to drop the Engine Cylinder and Engine Fuel Type based on this analysis from our original set of parameters.\n",
    "So our final model has the numerical parameters : Engine HP, Age of Car, log City MPG\n",
    "and the categorical parameters : Transmission Type, Driven Wheels, Vehicle Size, Vehicle Style and Make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to file\n",
    "pickle.dump(xgb_model, open(\"C:/users/hackuser1/carsales_xgb.pickle.dat\", \"wb\"))\n",
    "\n",
    "\n",
    "# load model from file\n",
    "#loaded_model = pickle.load(open(\"C:/users/hackuser1/carsales_xgb.pickle.dat\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda]",
   "language": "python",
   "name": "conda-env-Anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
